\section{Interpretability}
The challenge of interpreting a machine learning model is based upon the desire to understand how and why computers and algorithms work. When models can be interpreted, they can be improved as well. This is part of the learning process. First, feature selection with dimensionality reduction as main goal will be discussed. Then, research about feature importance as a goal itself will be covered.

\subsection{Feature selection}
Research has shown that using too many input features for machine learning will decrease performance (\cite{Trunk1979-sq}), especially when the number of training samples is not sufficient. This means that from a set of selected input features, a smaller subset of features as input could improve the model. 
\\Feature selections methods to find a representative set of features for the machine learning task at hand have been proposed by numerous researchers. Feature selection methods can be categorized in two types: \textit{wrappers} and \textit{filters}. 
\paragraph{A wrapper} feature selection algorithm is one that executes the models themselves to evaluate which features to use. Although this can be costly in terms of time consumption, this gives a purpose-specific and comparable result on features. The most extensive wrapper feature selection method would be to run the model with every possible subset of features (powerset) and pick the best subset.

\paragraph{A filter} feature selection algorithm is one that evaluates the features using heuristics based on assumptions of the data. The objective machine learning model is not used in this feature selection process. In practice this method is faster than a wrapper method, but if wrong assumptions are used, filter methods could lead to worse performance results. Examples of filter methods would be to exclude features with low variance or specific types. Also correlation-based feature selection has been proposed in research, like by \cite{Hall2000-bx}. This work proposed feature subset correlation analysis, showing that a filter would not have to be limited by a single feature at a time. Also, it has shown that application in both machine learning classification and regression can be improved by using feature selection.

~\\Feature selection is still a very important topic in machine learning. Especially in this era of big data, only finding the most representative features will improve the whole machine learning pipeline, from data mining to the actual performance of the models (\cite{Li2017-vo}). 
Also newer feature selection types for different data types were discussed, such as streaming data or heterogeneous data like multi-source, multi-view, linked data. However, these advanced data types are beyond the scope of this thesis. Feature selection for unstructured conventional data suffices. This leaves the following types of feature selection: similarity based, information-theoretical-based, sparse-learning-based, and statistical-based methods.

~\\In this thesis, filter based statistical-based methods and a wrapper based feature selection will be used. These methods filter out unwanted features in a simple and straightforward manner. Simple methods are still commonly used, even before applying other more sophisticated feature selection algorithms (\cite{Li2017-vo}).

\subsection{Feature importance}
One exemplary research on feature importance was one published in 1990 by \cite{Porter1990-is}. The goal of the research was to not only to learn to classify, but also explain why a classification had happened. A conceptual dialogue between an expert and their introduced system shows the importance of having explainable machine learning. This allowed for the expert to tweak certain weights and importances that were not correctly learn and reflect on the given suggestions by a machine learning model. Besides directly learnable binary relations (if A holds, then B must hold), the authors also discussed featural importances. Meaning that some features would have differential influence on other features or the classification (or regression) outcome. 
One of the main goals of statistical learning or analysis of machine learning models is to find the predictive features impact on the variable of interest, given that the prediction model performs reasonably well (\cite{Altmann2010-lq}). Common feature importance methods rely on the learned model coefficients, support vectors or other directly learnable parameters. However, when more complex and less studied methods are used, the direct inference of importances might become impossible. 

\paragraph{Permutation importance (\cite{Altmann2010-lq})} is a possible technique to analyze feature importance for complex machine learning models. The general idea proposed was that a permuted version of the features was used to train a model. Each feature $x$ was randomly permuted to break the association between the feature and the predictive outcome. Then, a comparison between the non-permuted value and the permuted value was made to see how the performance would increase or decrease by permutation (randomization for $x$). 

\paragraph{SHAP (SHapley Additive exPlanations) (\cite{Lundberg2017-wo})} is another promising technique to explain machine learning models. The Shapley value (\cite{Shapley1953-cc}) was a metric used in game theory to explain the utility of different users in multi-person game. This later was tailored to visualize and interpret the contribution of features on performance of a machine learning model (\cite{Lundberg2017-wo}). This method was able to explain which fraction of the performance can be attributed to which feature. 
Permutation feature importance is based on the decrease in model performance, whereas SHAP is based on magnitude of feature attributions.