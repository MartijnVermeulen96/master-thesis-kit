\section{Dataset profiling}
In this section dataset profiling will be discussed. Features need to be engineered to differentiate datasets in certain intrinsic properties. First, it will be covered on how a dataset profile could be of use for the estimation of performance of error detection strategies. Afterwards, different approaches and challenges for profiling relational data will be discussed.

%% REDS
% This is a direct descendant from the above schema matching ideas
\paragraph{REDS (\cite{Mahdavi2019-pk})} estimates the performance of error detection strategies based on datasets using their so-called "dirtiness profiles". It takes a number of samples from the dataset, extracts content, structure and quality features from this sample. Then it trains a regression model to predict the performance for each strategy. For \textbf{N} strategies, there will be \textbf{N} different models to predict the performance.
This is promising as their research did not require unrealistically large repositories. However, their estimation error was still increasing in their tests by adding more data profiles to the repository.
So a large repository could be possible and would lead to better estimations of performance of strategies.
The idea is also used in Raha \cite{Mahdavi2019-zf}, as a plugin, but the idea will be used in this research as a standalone recommendation for using error detection tools. The main idea is that similar datasets will have similar "dirtiness profiles". And similar datasets would require similar error detection methods. Key ideas from schema matching can be used to check for similarity between different datasets.

%% A survey of approaches to automatic schema matching
\paragraph{A survey of approaches to automatic schema matching (\cite{Rahm2001-ei})}. This research covers different schema matching approaches using a taxonomy. 
\blockquote{A fundamental operation in the manipulation of schema information is Match, which takes two schemas as input and produces a mapping between elements of the two schemas that correspond semantically to each other}
Historically, schema matching has been a part of 4 main processes. Schema integration (creating a global view of independent schemas), designing of source-to-warehouse transformations for raw input to a central warehouse with fixed schemas, e-commerce with a focus on message transformation and semantic query processing. 
The common divider in these processes, is the transformation of the input to some fixed known output.  
Then the research distinguished different approaches between schema and instance-level, element- and structure-level, and language and constraint-based matchers and discussed the combination of multiple matchers. Combining that with additional information (like dictionaries), will give a toolkit for matching schemas and showing similarities. 
Using all these tools with the purpose of error detection, could give insight on the performance of a tool on an unseen dataset, which has similar similarities to already known datasets.

%% Profiling relational data: a survey
\paragraph{Profiling relational data: a survey (\cite{Abedjan2015-ul})} 
Goes with a focus on determining metadata about a given dataset. One of the insights is on the challenges of data profiling: (i) managing the input, (ii) performing the computation, and (iii) managing the output. For different input shapes and types, some certain transformation will be done beforehand. Also computing the different steps of data profiling might differ based on different content types, schemas or even completely different documents. Then managing the output to be useful for a specific task is a challenge on itself. Depending on the task, limitations on the output can be existing. 

% Use case: Database reverse engineering
% Data quality / data cleansing
% Profiler: integrated statistical analysis and visualization for data quality assessment
%  Pipino, L., Lee, Y., Wang, R.: Data quality assessment. Commun
\todo{Nog doen, zitten}

% Automatic dependency discovery
% Multicolumn - single column

% Machine Learning techniques for regression/clustering