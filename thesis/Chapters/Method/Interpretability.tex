% RQ4
\section{Interpretability of tools}
\label{sec:interpretabilityoftools}
The prediction of performance of error detection tools gives another research direction, namely the dissection of this prediction.
Based on section \ref{sec:performanceprediction} and \ref{sec:toolranking}, with a set of input features and output values in the two tasks, the regression models can be analyzed to "explain" the inner workings of tools. Using feature importance identification methods depending on the specific regressor or general importance methods, the "weight" of a certain feature of the data profile can be translated to the performance of a certain tool with a specific configuration. The importance of features for each strategy can than be analyzed, to see if they correspond with the underlying techniques in these methods. If there are matches and mismatches, try to find why the misalignment occurs and see if improvements can be suggested for the error detection tools. A visual representation of making the error detection models interpretable, is shown in figure \ref{fig:method_interpret}.

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{thesis/Figures/Method/PerformanceEstimation-Interpretability.pdf}
    \caption{Adding interpretability into the flow of error detection}
    \label{fig:method_interpret}
\end{figure}

\subsection{Feature selection}
\label{subsec:featureselection}
Besides the learnable feature selection that will be used in the performance estimate pipeline of section \ref{sec:performanceprediction}, feature selection can also be done at the end of the estimation loop. Upon finding the most important features from the following section, a reduction of the dimensionality of the input to the estimator can be done, in order to improve the machine learning models, due to the curse of dimensionality otherwise. For this part, permutation importance will be used to determine which features contribute to better estimation. With this reduced number of features, the performance prediction of section \ref{sec:performanceprediction} will be repeated, to see if there is an improvement in estimation.

\subsection{Feature importance}
% According to the regression models
% Used as a proxy, something that is easy and quick to measure
Finding which data profile features are important for the regression model to estimate its performance, give insights to how a certain error detection strategy behaves.

To answer whether the dataset profile features could provide more insight on when and how the selected error detection tools perform correctly, the direct F1-score estimators from section \ref{sec:performanceprediction} will be analyzed using SHAP values. For each tool, the best performing configuration (highest mean F1-score) will be analyzed. First, the features with the highest impact on the estimator output will be inspected. Then, the correlation between the most impacting features and the SHAP contribution of that feature will be calculated to find if higher or lower feature values have positive or negative impact on the model outputs.