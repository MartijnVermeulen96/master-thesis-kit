\newpage
\section{Performance prediction}
To answer the second research question; \textit{Is it possible to create an extensive data profile to estimate performance on
unseen datasets?}; the results from the experiments as described in section \ref{sec:performanceprediction} will be showed in this section. 

\paragraph{Strategies to estimate} The goal is to predict the performance scores (recall, precision \& F1-score) for all datasets and strategies available. But, not all strategies were able to produce results that are meaningful enough to estimate. From all the executed strategies, only strategies with an average F1-score for all datasets over 0 will be kept. Also, as shown in figure \ref{fig:number_configs_runs}, not all strategies were able to produce correct results for all the datasets. As the estimation of performance results can only be done by learning from training examples, a certain amount of training samples is necessary to generate and test the estimations. Only strategies that generated results for more than 10 datasets (at least 75\% of the datasets), will be discarded for the next steps of the research. Also, for Raha, only the strategies with fully accurate human labeling simulation are taken into account. The remaining number of strategies per tool are shown in table \ref{tab:num_configs_per_tool_filtered}. In total, there are 1157 dataset-strategy pairs that will be used as input and output for training and testing. 

\begin{table}
\centering
\begin{tabular}{lr}
\toprule
Tool         &  \# of configurations \\
\midrule
dBoost            &    60 \\
Raha              &    20 \\
ForbiddenItemSets &     7 \\
FAHES             &     3 \\
KATARA            &     2 \\
ActiveClean       &     1 \\
\bottomrule
\end{tabular}
\caption{Number of configurations per tool filtered with \\F1-score > 0 and at least 75\% completion}
\label{tab:num_configs_per_tool_filtered}
\end{table}

\paragraph{Estimation pipeline selection} As discussed in subsection \ref{subsec:estimatorselection}, an estimator pipeline will be constructed based on different regression models. The pipeline exists of four stages:
\begin{enumerate}
    \item Feature normalization/standardization (optional)
    \item Feature selection (optional)
    \item Principle component analysis (optional)
    \item Regression model (required)
\end{enumerate}

For each performance score, one estimation pipeline setting is chosen using the minimum mean square error of estimations. In each of the following subsections, the best specific estimator pipeline is discussed and the estimation results are shown. Also, the estimation errors are shown and discusses, to understand how the estimator performs.

\subsection{Precision estimation}
For the precision estimation, the best scoring estimation pipeline was:
~\\Dataset profiles $\rightarrow$ Feature normalization $\rightarrow$ Gradient Boosting Regressor
\\No principle component analysis or feature selection was done. 

~\\In figure \ref{fig:prec_estimation_errors}, the distribution of estimation errors for the precision is shown. Each count represents a single estimation of the precision of a error detection strategy (tool + configuration) and a specific dataset, using the leave-one-out error. In the figure, it shows that for the precision, most of the estimations are slightly over the real values. The peak is just over 0. The median for the estimation errors is 0.0046 and the mean is -0.0092. This shows that overall, more precision estimates are over-estimations, but some of the worse estimations are underestimations (negative values). 
~\\The mean square error is 0.0543 and the median absolute error is 0.0949. This means that for most of the strategy-dataset pairs, it was capable of estimating the precision within an error of 0.1. 

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{thesis/Figures/RQ2/15_error_histogramcell_prec.pdf}
    \caption{Precision estimation errors distribution}
    \label{fig:prec_estimation_errors}
\end{figure}

To put these scores in perspective, if all a random estimator would only output 0.5 as estimated precision, the mean square error would be 0.1646 and the absolute median error would be 0.45. Whereas for the selected estimator above, the estimations would make sense, having an error of around 0.45 would not provide any beneficial information before running an error detection strategy. 

\subsection{Recall estimation}
For the recall estimation, the best scoring estimation pipeline was:
~\\Dataset profiles $\rightarrow$ Select best 2 features $\rightarrow$ 3 nearest neighbours regression
\\No principle component analysis was done. 

~\\In figure \ref{fig:rec_estimation_errors}, the distribution of estimation errors for the recall is shown. The best estimator pipeline for estimating the recall performs worse than it does for the precision. A mean square error 0.1045 and mean absolute error of 0.166 is achieved. The lower estimation performance can be caused by the distribution of real recall performance scores. There are around 70 dataset-strategy pairs scoring between 0 and 0.1, and approximately 300 between 0.9 and 1. Because a high recall can be achieved by marking all the cells as erroneous, this spike in the high recall score is bigger than it is with the precision estimation (around 600 between 0 and 0.1 and 50 between 0.9 and 1). Because it is easier to achieve high recall (at the cost of precision), the specific might not determine the recall of an error detection strategy as much, so it might be harder to train an estimator.

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{thesis/Figures/RQ2/15_error_histogramcell_rec.pdf}
    \caption{Recall estimation errors distribution}
    \label{fig:rec_estimation_errors}
\end{figure}

\subsection{F1-score estimation}
% Direct vs combined
\subsubsection{Direct estimation}
For the direct F1 estimation, the best scoring estimation pipeline was:
~\\Dataset profiles $\rightarrow$ Feature standardization $\rightarrow$ PCA with RBF-kernel to 2 dimensions $\rightarrow$ Support Vector Regression

The errors of estimation are displayed in figure \ref{fig:f1_estimation_errors}. With a mean square error of 0.0442 and median absolute error of 0.1006, this estimator is performing generally the best of the presented estimators, with respect to the mean square error. This best estimator for directly estimating the F1 score is mostly over-estimating values with small error margin.  

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{thesis/Figures/RQ2/15_error_histogramcell_f1.pdf}
    \caption{F1 estimation errors distribution}
    \label{fig:f1_estimation_errors}
\end{figure}

\subsubsection{Combined estimation}
The combined estimator is the using the best estimator pipelines from the precision and recall together to output an F1-score. The error distribution is shown in figure \ref{fig:combined_f1_estimation_errors}. The main noticeable finding is that the distribution shifted more towards the center, performing better in general than the direct F1 score estimator. With a median absolute error of only 0.0790, it outperforms the direct estimator for most of the samples, but due to the under-estimated outliers on the left of figure \ref{fig:combined_f1_estimation_errors}, the mean square error is neglectably higher (0.0452). 

\begin{figure}
    \centering
    \includegraphics[width=0.8\textwidth]{thesis/Figures/RQ2/15_error_histogramcell_f1_combined.pdf}
    \caption{Combined F1 estimation errors distribution}
    \label{fig:combined_f1_estimation_errors}
\end{figure}

\subsection{Results per tool}
To verify how the specific estimators perform for each tool, the mean squared error grouped for each tool is shown in figure \ref{fig:mse_combined_f1_tool}. It shows that for Raha, the best performing tool, has the highest mean square error. ActiveClean follows in the highest error. This could imply that it is harder to estimate error detection strategies with a human in the loop. Also, both Raha and ActiveClean are based on partially random sampling for the human labeling, which could give different results for different runs. Lastly, the fact that Raha performs best overall, also contributes to possible over-estimations for a dataset like "restaurants", where no tool performed better than 0.01 F1-score. 

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{thesis/Figures/RQ2/15_tools_combined_f1.pdf}
    \caption{Mean squared error for combined F1 estimation, grouped on tool}
    \label{fig:mse_combined_f1_tool}
\end{figure}